name: Scrape Sites from Config

on:
  schedule:
    # Run every 4 hours
    - cron: '0 */4 * * *'
  workflow_dispatch: # Allow manual triggering

jobs:
  scrape-all:
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Install Flox
        uses: flox/install-flox-action@v3

      - name: Setup environment with Flox
        run: |
          # Create a basic flox environment with uv
          flox init
          flox install uv

      # For users who want to use the published package:
      # - name: Install watcher from GitHub
      #   run: uv pip install git+https://github.com/gpwclark/watcher.git

      # For development/this repo:
      - name: Install dependencies
        run: flox activate -- uv sync

      - name: Run batch scraper
        run: |
          # Auto-construct base URL from GitHub context
          BASE_URL="https://github.com/${{ github.repository }}/blob/${{ github.ref_name }}"

          # Run watcher-batch with sites.toml
          flox activate -- uv run watcher-batch --config sites.toml --base-url "$BASE_URL"

      - name: Commit changes
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"

          # Add any changes
          git add feeds/ content/ || true

          # Commit if there are changes
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "Update feeds from sites.toml: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
            git push
          fi
